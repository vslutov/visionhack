{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger, LearningRateScheduler\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "\n",
    "from data_generator import WrapperImageDataGenerator, custom_generator, get_weights\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "IMAGES_ON_TRAIN = 44183 // 4\n",
    "IMAGES_ON_VALIDATION = 10966 // 4\n",
    "\n",
    "TRAIN_DATA_DIR = '/home/vs/Source/visionhack/data/trainset/data_to_fit_with_weight_train/'\n",
    "VALID_DATA_DIR = '/home/vs/Source/visionhack/data/trainset/data_to_fit_with_weight_valid/'\n",
    "IMAGE_SHAPE = (139, 221)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_generator = custom_generator('data/trainset/data_to_fit_with_weight_train/', IMAGE_SHAPE, BATCH_SIZE)\n",
    "valid_generator = custom_generator('data/trainset/data_to_fit_with_weight_valid/', IMAGE_SHAPE, BATCH_SIZE)\n",
    "weights = get_weights('data/trainset/data_to_fit_with_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_DATA_DIR = 'data/models'\n",
    "LR = 0.045\n",
    "\n",
    "#callbacks\n",
    "checkpoint_path = 'checkpoints_weights.{epoch:02d}-{val_loss:.2f}.hdf5'\n",
    "checkpoint_path = os.path.join(MODEL_DATA_DIR, checkpoint_path)\n",
    "checkpointer = ModelCheckpoint(filepath=checkpoint_path, verbose=1, period=1)\n",
    "\n",
    "stoper = EarlyStopping(min_delta=0.001, patience=7)\n",
    "\n",
    "reducer = LearningRateScheduler(lambda e: LR * 0.94 ** (e // 2))\n",
    "\n",
    "log_path = 'log.csv'\n",
    "log_path = os.path.join(MODEL_DATA_DIR, log_path)\n",
    "logger = CSVLogger(filename=log_path, append=True)\n",
    "\n",
    "callbacks = [checkpointer, stoper, reducer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(input_shape=(IMAGE_SHAPE[0], IMAGE_SHAPE[1], 3), weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "#x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(10, activation='sigmoid')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "# model.summary()\n",
    "# model.load_weights('data/models/finetuned_checkpoints_weights.02-0.11.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/172 [============================>.] - ETA: 2s - loss: 0.4289 - mean_squared_error: 0.1294Epoch 00000: saving model to data/models/checkpoints_weights.00-0.44.hdf5\n",
      "172/172 [==============================] - 502s - loss: 0.4287 - mean_squared_error: 0.1294 - val_loss: 0.4424 - val_mean_squared_error: 0.1341\n",
      "Epoch 2/100\n",
      "171/172 [============================>.] - ETA: 2s - loss: 0.3870 - mean_squared_error: 0.1126Epoch 00001: saving model to data/models/checkpoints_weights.01-0.40.hdf5\n",
      "172/172 [==============================] - 482s - loss: 0.3868 - mean_squared_error: 0.1125 - val_loss: 0.3968 - val_mean_squared_error: 0.1170\n",
      "Epoch 3/100\n",
      "171/172 [============================>.] - ETA: 2s - loss: 0.3755 - mean_squared_error: 0.1081Epoch 00002: saving model to data/models/checkpoints_weights.02-0.36.hdf5\n",
      "172/172 [==============================] - 483s - loss: 0.3755 - mean_squared_error: 0.1080 - val_loss: 0.3593 - val_mean_squared_error: 0.1014\n",
      "Epoch 4/100\n",
      "171/172 [============================>.] - ETA: 2s - loss: 0.3721 - mean_squared_error: 0.1070Epoch 00003: saving model to data/models/checkpoints_weights.03-0.37.hdf5\n",
      "172/172 [==============================] - 484s - loss: 0.3723 - mean_squared_error: 0.1071 - val_loss: 0.3685 - val_mean_squared_error: 0.1073\n",
      "Epoch 5/100\n",
      "171/172 [============================>.] - ETA: 2s - loss: 0.3670 - mean_squared_error: 0.1050Epoch 00004: saving model to data/models/checkpoints_weights.04-0.36.hdf5\n",
      "172/172 [==============================] - 473s - loss: 0.3669 - mean_squared_error: 0.1049 - val_loss: 0.3575 - val_mean_squared_error: 0.1032\n",
      "Epoch 6/100\n",
      "171/172 [============================>.] - ETA: 2s - loss: 0.3670 - mean_squared_error: 0.1051Epoch 00005: saving model to data/models/checkpoints_weights.05-0.35.hdf5\n",
      "172/172 [==============================] - 482s - loss: 0.3670 - mean_squared_error: 0.1051 - val_loss: 0.3483 - val_mean_squared_error: 0.0988\n",
      "Epoch 7/100\n",
      "171/172 [============================>.] - ETA: 2s - loss: 0.3614 - mean_squared_error: 0.1029Epoch 00006: saving model to data/models/checkpoints_weights.06-0.36.hdf5\n",
      "172/172 [==============================] - 484s - loss: 0.3613 - mean_squared_error: 0.1028 - val_loss: 0.3596 - val_mean_squared_error: 0.1028\n",
      "Epoch 8/100\n",
      "171/172 [============================>.] - ETA: 2s - loss: 0.3636 - mean_squared_error: 0.1041Epoch 00007: saving model to data/models/checkpoints_weights.07-0.37.hdf5\n",
      "172/172 [==============================] - 472s - loss: 0.3639 - mean_squared_error: 0.1042 - val_loss: 0.3716 - val_mean_squared_error: 0.1089\n",
      "Epoch 9/100\n",
      " 32/172 [====>.........................] - ETA: 274s - loss: 0.3661 - mean_squared_error: 0.1049"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-afd16080242c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mIMAGES_ON_VALIDATION\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                     initial_epoch=0)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2009\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# model.summary()\n",
    "    \n",
    "optimizer = RMSprop(lr=LR, decay=0.9, epsilon=1)\n",
    "    \n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['MSE'])\n",
    "\n",
    "model.fit_generator(train_generator, \n",
    "                    epochs=EPOCHS,\n",
    "                    steps_per_epoch = int(IMAGES_ON_TRAIN / BATCH_SIZE),\n",
    "                    verbose=1, \n",
    "                    validation_data=valid_generator,\n",
    "                    callbacks=callbacks,  \n",
    "                    validation_steps=int(0.1 * IMAGES_ON_VALIDATION / BATCH_SIZE), \n",
    "                    class_weight=weights, \n",
    "                    initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "import os\n",
    "import tqdm\n",
    "import skvideo.io\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import numpy as np\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from test import predict_labels\n",
    "\n",
    "labels = [\"z\", \"c\", \"m\", \"t\", \"d\", \"b\", \"e\", \"x\", \"f\"]\n",
    "meaning_labels = [\"zebra\", \"zebra sign\", \"bridge\", \"under bridge\", \"wiper\", \"bump\", \"city enter\", \"city exit\", \"bump sign\"]\n",
    "\n",
    "video_path = 'data/trainset/video/akn.031.029.left.avi'\n",
    "Y = predict_labels(video_path, model, IMAGE_SHAPEIMAGE_SHAPE, )\n",
    "c_images, c_class = Y.shape\n",
    "for i in range(c_class):\n",
    "    y = Y[:, i]\n",
    "    plt.figure(figsize=(12, 2))\n",
    "    plt.plot(range(c_images), y, 'bs')\n",
    "    plt.title(meaning_labels[-i])\n",
    "    plt.ylim((0, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINETUNE_EPOCHS = 100\n",
    "FINETUNE_LR = 0.0001\n",
    "\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "\n",
    "optimizer = RMSprop(lr=LR, decay=0.9, epsilon=1)\n",
    "    \n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['MSE'])\n",
    "\n",
    "model.fit_generator(train_generator, \n",
    "                    epochs=EPOCHS,\n",
    "                    steps_per_epoch = int(IMAGES_ON_TRAIN / BATCH_SIZE),\n",
    "                    verbose=1, \n",
    "                    validation_data=valid_generator,\n",
    "                    callbacks=callbacks,  \n",
    "                    validation_steps=int(0.1 * IMAGES_ON_VALIDATION / BATCH_SIZE), \n",
    "                    class_weight=None, \n",
    "                    initial_epoch=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
